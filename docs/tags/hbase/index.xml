<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HBase on Just4Fun</title>
    <link>https://hujianxin.github.io/blog/tags/hbase/</link>
    <description>Recent content in HBase on Just4Fun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jun 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hujianxin.github.io/blog/tags/hbase/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>LSM Tree</title>
      <link>https://hujianxin.github.io/blog/posts/lsm/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hujianxin.github.io/blog/posts/lsm/</guid>
      <description>LSM Tree是HBase使用的数据存储结构。主要原因是，HBase基于HDFS作为底层文件存储，而HDFS不支持随机写，只支持顺序写。而LSM Tree可以轻松应对这种使用场景。
随机写磁盘会导致大量的磁盘寻道，影响写入效率，LSM本身是顺序写入，在磁盘写入方面具有先天优势。另外，有些写多读少的应用场景也非常适合使用LSM Tree。
HBase的LSM Tree实现 在HBase设计中，数据分为两部分：MemStore、DiskStore。
新写入的数据直接写入MemStore，但是为了防止数据丢失，会写一条WAL。当MemStore达到一定的阈值，将其设置只读，并新建一个新的MemStore用来写入，只读的MemStore会被异步的刷成一个DiskStore。
HBase的compaction LSM Tree实现的系统，因为是append only的设计，所以compact是必须的过程。HBase中，分为两种compact：minor compact，major compact
minor compact minor compact是选取部分小的、相邻的HFile，合并成一个大的HFile
major compact major compact，是将整个DiskSotre合并成一个HFile，合并过程中，会删除：过期数据、已经打了删除标记的数据、版本号超额的数据。
分层压缩：LevelDB的LSM Tree实现 LevelDB也是使用了LSM Tree的设计，但是他的compact过程与HBase不同，采用了分层压缩的设计。
如上图所示：
 Level0层，是由ImmutableMem Table dump出来的。所以Level0层不同文件可能会有重叠的。 Level n是由level n-1和level n层compact出来的。 读数据时，顺序是内存-&amp;gt;Level0-&amp;gt;Level1-&amp;gt;Level&amp;hellip;，在查询Level0时，需要查询多个文件，查询其他层时，只需要查询特定文件。  </description>
    </item>
    
    <item>
      <title>HBase BulkLoad</title>
      <link>https://hujianxin.github.io/blog/posts/buildload/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hujianxin.github.io/blog/posts/buildload/</guid>
      <description>在使用HBase的业务中，很多对HBase写数据的离线任务，因为数据量非常大，可能会造成下面的结果：
 RegionServer频繁flush，从而频繁compact、split，进而影响集群性能。 RegionServer频繁gc。 抢占大量Cpu、内存、IO、带宽资源。 甚至会耗尽RegionServer的线程，导致集群阻塞。  以上问题，会影响到离线任务之外的线上任务，很多情况下，这是不能容忍的。所以HBase提供了BulkLoad模式解决这个问题。
BulkLoad方法是通过MapReduce来直接写HFile，跳过了HBase的处理流程。就像在读HBase时候使用Snapshot一样。
BulkLoad核心流程 BulkLoad主要分为两大阶段：HFile生成阶段、HFile导入阶段。
一般去网上搜或者书上介绍的关于BulkLoad相关的文章，在介绍File生成的时候，都会介绍一种非常简单通用的方式，也就是通过MapReduce的方式生成HFile，但是其实HBase核心的BulkLoad过程是不包括HFile生成的，而是HFile导入阶段。
所以说，HFile的生成可以是任何形式的，并不一定是大家所使用的MapReduce形式。
下上面我分别说一下两种不同的方式。
MapReduce生成HFile 因为官方提供了HFileOutputFormat2.configureIncrementalLoad这个工具，所以使用MapReduce方式非常简单，核心代码如下：
public class BulkLoadJob { static Logger logger = LoggerFactory.getLogger(BulkLoadJob.class); public static class BulkLoadMap extends Mapper&amp;lt;LongWritable, Text, ImmutableBytesWritable, Put&amp;gt; { public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { String[] valueStrSplit = value.toString().split(&amp;#34;,&amp;#34;); String hkey = valueStrSplit[0]; String family = valueStrSplit[1].split(&amp;#34;:&amp;#34;)[0]; String column = valueStrSplit[1].split(&amp;#34;:&amp;#34;)[1]; String hvalue = valueStrSplit[2]; /** * 只支持单列族并发写入，如果是多个列族得多write一次 */ final byte[] rowKey = Bytes.</description>
    </item>
    
    <item>
      <title>HBase Snapshot</title>
      <link>https://hujianxin.github.io/blog/posts/snapshot/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hujianxin.github.io/blog/posts/snapshot/</guid>
      <description>之前将过BulkLoad可以离线的写入HBase，并且不会出发HBase的写流程，从而减轻HBase的压力、提高写入速度。在读取HBase的时候，也有一个机制，可以直接绕过HBase的读取流程，直接读取HFile，也就是Snapshot机制。
Snapshot原本是为了快速备份HBase设计的。但是我们使用这个功能来快速扫表，效果惊艳。
Snapshot技术基础原理 为什么Snapshot可以做到这么快呢？主要是因为HBase给表打Snapshot的时候，并没有真正的备份数据，生成了原始数据的一个指针。
能这样做得益与HBase落盘的数据都不会再修改，直到compact。
所以Snapshot的总体流程是这样的：
 Memstore flush生成新文件 对当前所有的Hfile建立引用指针。  Snapshot具体流程 Snapshot是由客户端发起的，但是真正执行这一动作的是RegionServer，RegionServer非常多，这会导致Snapshot的事务问题，HBase通过两阶段提交来解决这个问题：
我们都知道两阶段提交的过程包括：
 协调者发起prepare，等待ack 执行者准备环境，发送ack 协调者收到所有的ack之后，发起commit  具体到Snapshot的实现中，两阶段提交主要是通过Zk为媒介进行的。
Snapshot具体实现 前面将了Snapshot的流程，其中重要概念就是这个引用文件。
引用文件主要包含了region的元数据，HFile文件名等。
Snapshot之后遇到Compaction 前面说到，snapshot文件只是真实HFile的引用文件，如果发生compaction之后，原文件不在了，snapshot如何保证不失效的呢？
HBase 的做法很简单，就是在compact之前，将原始数据转移到archive目录里面。</description>
    </item>
    
    <item>
      <title>HBase 集群复制</title>
      <link>https://hujianxin.github.io/blog/posts/hbase_replication/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hujianxin.github.io/blog/posts/hbase_replication/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>